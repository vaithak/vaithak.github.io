var store = [{
        "title": "Counting Linear Extensions: GSoC Project Overview",
        "excerpt":"I have been selected as a student developer in Google Summer of Code under the GeomScale organization &amp; will be spending the upcoming 10 Weeks working on the project of “Counting Linear Extensions”. This post will be for providing details regarding my project, mainly problem formulation and proposed solution. +...","categories": [],
        "tags": ["gsoc"],
        "url": "/gsoc-project-overview-part1/",
        "teaser": "/assets/images/gsoc.png"
      },{
        "title": "Automatic Differentiation",
        "excerpt":"Given a continuos function $f(x)$, how do you compute it’s derivative $f’(x_0)$ for a particular input $x_0$ computationally? Similarly, for a vector valued function $f(\\vec{\\boldsymbol{x}})$, how do we compute its gradient $\\nabla_{\\vec{\\boldsymbol{x_0}}} f(\\vec{\\boldsymbol{x}})$? Where $\\vec{\\boldsymbol{x}}$ is an $n$ dimensional vector and $$ \\nabla f(\\vec{\\boldsymbol{x}}) = [ \\frac{\\partial f}{\\partial x_0}, \\frac{\\partial...","categories": [],
        "tags": ["autodiff"],
        "url": "/autodiff-clad/",
        "teaser": "/assets/images/llvm.png"
      },{
        "title": "Vectorized Automatic Differentiation",
        "excerpt":"In the last post, we discussed techniques for computing derivatives (or gradients) of arbitrary computational functions, with automatic differentiation (AD) being the most generic approach; i.e., it works for any function, even those containing control flow statements like for-loops and if-conditions. This post will discuss how we can vectorize that...","categories": [],
        "tags": ["autodiff"],
        "url": "/vectorized-autodiff-clad/",
        "teaser": "/assets/images/partial-derivative.png"
      }]
